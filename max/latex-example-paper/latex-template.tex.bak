\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}	% For figure environment


\begin{document}
\title{PCML Project 1}

\author{
  Maximilian Mordig, Yoam, ...\\
  \textit{EPFL Lausanne}
}

\maketitle

\begin{abstract}
  In this report, we report our results applying machine learning algorithms to a CERN dataset to detect Higgs bosons. We have a validation list which allows us to calibrate our models. We apply both linear regression with polynomial features (including cross-features) and logistic regression. For both, we use regularization and perform cross-validation over the regularization parameter $\lambda$, the degrees (for non-cross features), the degrees for cross-features, averaging all over a number of seeds used to select the training and the testing set. The best score we achieved was $81.153\%$ with linear regression. Understanding the physics behind the measurement may definitely be a key to improve upon the results.
\end{abstract}

\section{Introduction}

The provided training dataset consists of 250000 data rows, each row contains 30 features and a prediction whether a particular confirms or rejects the presence of the Higgs boson.

\subsection{Data Exploration}
Before trying to fit a linear regression or similar to the data, it is important to get a rough idea of how it looks like. 

We start by looking at the number of NaNs per column. We see that there are about seven features with 175000 NaNs values out of the total 250000 NaNs, as seen in figure \ref{fig:NaNsPerFeatures}. In the end, we choose to remove no features (based on too many NaN values) because this deteriorates the results. It seems that they contain useful information as the figure shows (comparing the data where the Higgs boson is detected and where it is not detected). In the code, we chose not to loop over this as well because the code will take too much time (do it yourself if you wish).

\begin{figure}[tbp]
  \centering
  %\includegraphics[width=\columnwidth]{Images/NAPerColumn.pdf}
  \caption{Number of NaN values in the data for each feature.}
  \vspace{-3mm}
  \label{fig:NaNsPerFeatures}
\end{figure}

Instead of removing the features with too many NaN values, we choose to replace them by the median of the values of the feature. The median is more robust than the mean. This improves over the method where no preprocessing at all is applied.

The interesting thing is that roughly $30\%$ of the provided data has a predicted Higgs boson, hence the trivial estimator can just assign "not predicted" to each data row which gives an overall prediction success of $70\%$. Hence, the benchline is to perform better than $70\%$ of correct predictions. With no preprocessing of the data at all (no replacement or removal of the data with NaN values), just standardizing the data to have zero mean and unit variance, we achieved $74\%$ of success (according to the Kaggle platform).

\subsection{Applying PCA}
Because the model becomes quite complex as the number of features increases, we implemented PCA (principal component analysis) to reduce the number of features. Choosing to keep a variance of $0.9999$ reduces the $30$ features to $15$ features. We further plotted histograms for each of the features that we kept to check they do not exhibit any odd behaviour or if anything is special that distinguishes data with the Higgs boson from the data without the Higgs boson. We also plotted the cross-dependence for each pair of features, but it is difficult for us to extract the features from the plots in an efficient way. In other words, we did not use these plots except for gross error checking. We did not notice anything special. See the ipynb notebook file for the plots or the "Images" directory in the same folder.


\subsection{Adding Polynomial Features Including Cross-Features}
We consequently added polynomial non-cross-related features and did cross-validation on them. But we thought that given the correlation figures we had produced before, there seemed some significant correlation. Hence, we programmed a method to also generate cross-features. For instance, for features $\{x, y\}$, we generate the features $\{1, x, y, x^2, xy, y^2, x^3, x^2y, xy^2, y^3\}$ up to degree $3$. We explicitly avoid duplicates $xy$ and $yx$, which would both be created in a naive approach, by relying on the unique factorization of primes (our own idea, see the code for this) to generate a mask that picks exactly one among $\{xy,yx\}$. In the program, we generate the cross-related features from degree $0$ to some degree $d_{\textrm{cross}}$ and then continue to generate the non-cross-related features from degree $d_{\textrm{cross}}+1$ to $d$. In a better approach, to avoid computation complexity and overfitting, one could bring in the patterns observed from the correlations graphs by eye, but this limits the systematic applicability of the model.

We are aware of the fact that the cross-related features introduce a lot more complexity to the model. To avoid overfitting, we rely on the cross-validation rejecting the overfitted models. Practically, we split the provided data into $5\%$ of training data and $95\%$ of testing data, which should be enough for detecting overfitted models.

\subsection{Using Cross-Validation to Select the Best Model}
As mentioned above, the most important is the model selection among the class of possible models using k-cross-validation with $k=5$. We also plotted the cross-validation error using the variance-bias decomposition from the exercises. The list of models has become quite large. Each generated model depends on the cross-feature degree $d_{cross}$, the polynomial degree $d$, the regularization parameter $\lambda$, which features to remove from the very start, the variance to keep for the PCA dimensionality reduction. Additionally, there is another loop to average over the seeds used to select the testing and training sets for cross-validation. We were forced to decide to remove some complexity. 

Changing one parameter at a time (ceteris paribus) and running cross-validation, we decided not to remove any features with too many NaN values and to keep $0.9999$ of the variance (total of 1) with PCA. With the NaN values, we achieved the best testing error estimates on the provided dataset, but scored worse on Kaggle. We interpret the removal of features as being too biased towards the provided data sample. What concerns the PCA, we were forced to reduce the dimensionality, so we thought, keeping $15$ features with a retained variance of $0.9999$ is still fine. For the seeds, we noticed that the training and testing errors do not change very much, so we restricted to two seeds (this is risky, but it takes too much time otherwise).

We also fixed the cross-feature degree to $d_{cross} = 3$, achieving best overall cross-validation results among all cross-features degrees. We checked this manually instead of putting a loop around it. In the code, we have the following loops: over the seeds, over the (non-cross-feature) degrees and over $\lambda$ (to select the best $\lambda$ for a given degree).

Due to the polynomial (cross and non-cross) features, our model has a lot of variables in the end and the prediction of the test file ('test.csv') for the Kaggle platform may encounter memory errors. That is why we are predicting and writing the data in chunks.

Finally, we always used the exact method to compute the weights (involving matrix inversion). We found that the direct method was faster than (stochastic) gradient descent and more reliable. For the cross-validation, we question whether it is good to select the method with least error or rather the method with best prediction accuracy (still using the least squares function for computing the weights).

\subsection{Applying Logistic Regression}
We also tried to apply logistic regression, but we did not get very good results with it. This time, there was no exact formula available and we had to use stochastic gradient descent, which we checked was better than pure gradient descent. To check the algorithm, we compared the computed gradient with the approximated gradient (using a central finite-difference formula) and we got quite different results. We cannot exclude errors although we checked several times. The reason the numerical gradient does not equal the analytical gradient might be computational inaccuracy due to small numbers, but we tried to pay attention to this by rewriting the involved sigmoid function $\sigma(x) = \frac{e^{-x}}{1+e^{-x}} = \frac{1}{1+e^{x}}$ and/or approximating $ln(1+e^x)\approx x$ for large $x \geq 10$.

\subsection{Possibility for Improvements and Outlook}
We obtained $81\%$ success with our method presented here, which is not that bad.
However, the machine learning approach to select the features appears very brutal to us. It was definitely a good idea to introduce cross-feature features, but greater care should be taken, which features to combine as this might significantly reduce the model complexity. We had another implementation of logistic regression (but forgot to commit it), where we achieved 80\%, which appears strange to us because logistic regression should be better.

With the polynomial features, we are for instance not able to capture a more complex relationship like an exponential or a logarithm. It would definitely prove useful to understand the physical significance of the provided measurements and develop an approximate parametrized physical model which we then fit with machine learning. In the end, we are not content with $81\%$ because we would at least need $99\%$ prediction accuracy because other indirect methods of detecting the Higgs boson are scarce.



The aim of writing a paper is to infect the mind of your reader with
the brilliance of your idea~\cite{jones08}. 
The hope is that after reading your
paper, the audience will be convinced to try out your idea. In other
words, it is the medium to transport the idea from your head to your
reader's head. 
In the following
section, we show a common structure of scientific papers and briefly
outline some tips for writing good papers in
Section~\ref{sec:tips-writing}.

At that
point, it is important that the reader is able to reproduce your
work~\cite{schwab00,wavelab,gentleman05}. This is why it is also
important that if the work has a computational component, the software
associated with producing the results are also made available in a
useful form. Several guidelines for making your user's experience with
your software as painless as possible is given in
Section~\ref{sec:tips-software}.

This brief guide is by no means sufficient, on its own, to
make its reader an accomplished writer. The reader is urged to use the
references to further improve his or her writing skills.

\section{The Structure of a Paper}
\label{sec:structure-paper}

Scientific papers usually begin with the description of the problem,
justifying why the problem is interesting. Most importantly, it argues
that the problem is still unsolved, or that the current solutions are
unsatisfactory. This leads to the main gist of the paper, which is
``the idea''. The authors then show evidence, using derivations or
experiments, that the idea works. Since science does not occur in a
vacuum, a proper comparison to the current state of the art is often
part of the results. Following these ideas, papers usually have the
following structure:
\begin{description}
\item[Abstract] \ \\
  Short description of the whole paper, to help the
  reader decide whether to read it.
\item[Introduction] \ \\
  Describe your problem and state your
  contributions.
\item[Models and Methods] \ \\
  Describe your idea and how it was implemented to solve
  the problem. Survey the related work, giving credit where credit is
  due.
\item[Results] \ \\
  Show evidence to support your claims made in the
  introduction.
\item[Discussion] \ \\
  Discuss the strengths and weaknesses of your
  approach, based on the results. Point out the implications of your
  novel idea on the application concerned.
\item[Summary] \ \\
  Summarize your contributions in light of the new
  results.
\end{description}


\section{Tips for Good Writing}
\label{sec:tips-writing}

The ideas for good writing have come
from~\cite{editor10,jones08,anderson04}.

\subsection{Getting Help}
One should try to get a draft read by as many friendly people as
possible. And remember to treat your test readers with respect. If
they are unable to understand something in your paper, then it is
highly likely that your reviewers will not understand it
either. Therefore, do not be defensive about the criticisms you get,
but use it as an opportunity to improve the paper. Before your submit
your friends to the pain of reading your draft, please \emph{use a
  spell checker}.

\subsection{Abstract}
The abstract should really be written last, along with the title of
the paper. The four points that should be covered~\cite{jones08}:
\begin{enumerate}
\item State the problem.
\item Say why it is an interesting problem.
\item Say what your solution achieves.
\item Say what follows from your solution.
\end{enumerate}

\subsection{Figures and Tables}

\begin{figure}[tbp]
  \centering
  \includegraphics[width=\columnwidth]{denoised_signal_1d}
  \caption{Signal compression and denoising using the Fourier basis.}
  \vspace{-3mm}
  \label{fig:denoise-fourier}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{local_wdenoised_1d}
  \vspace{-3mm}
  \caption{Signal compression and denoising using the Daubechies wavelet basis.}
  \label{fig:denoise-wavelet}
\end{figure}

Use examples and illustrations to clarify ideas and results. For
example, by comparing Figure~\ref{fig:denoise-fourier} and
Figure~\ref{fig:denoise-wavelet}, we can see the two different
situations where Fourier and wavelet basis perform well. 

\subsection{Models and Methods}
The models and methods
section should describe what was
done to answer the research question, describe how it was done,
justify the experimental design, and
explain how the results were analyzed.

The model refers to the underlying mathematical model or structure which 
you use to describe your problem, or that your solution is based on. 
The methods on the other hand, are the algorithms used to solve the problem. 
In some cases, the suggested method directly solves the problem, without having it 
stated in terms of an underlying model. Generally though it is a better practice to have 
the model figured out and stated clearly, rather than presenting a method without specifying 
the model. In this case, the method can be more easily evaluated in the task of fitting 
the given data to the underlying model.

The methods part of this section, is not a step-by-step, directive,
protocol as you might see in your lab manual, but detailed enough such
that an interested reader can reproduce your
work~\cite{anderson04,wavelab}.

The methods section of a research paper provides the information by
which a study's validity is judged.
Therefore, it requires a clear and precise description of how an
experiment was done, and the rationale
for why specific experimental procedures were chosen.
It is usually helpful to
structure the methods section by~\cite{kallet04methods}:
\begin{enumerate}
\item Layout the model you used to describe the problem or the solution.
\item Describing the algorithms used in the study, briefly including
  details such as hyperparameter values (e.g. thresholds), and
  preprocessing steps (e.g. normalizing the data to have mean value of
  zero).
\item Explaining how the materials were prepared, for example the
  images used and their resolution.
\item Describing the research protocol, for example which examples
  were used for estimating the parameters (training) and which were
  used for computing performance.
\item Explaining how measurements were made and what
  calculations were performed. Do not reproduce the full source code in
  the paper, but explain the key steps.
\end{enumerate}

\subsection{Results}

Organize the results section based on the sequence of table and
figures you include. Prepare the tables and figures as soon as all
the data are analyzed and arrange them in the sequence that best
presents your findings in a logical way. A good strategy is to note,
on a draft of each table or figure, the one or two key results you
want to address in the text portion of the results.
The information from the figures is
summarized in Table~\ref{tab:fourier-wavelet}.

\begin{table*}[htbp]
  \centering
  \begin{tabular}[c]{|l||l|l|l|}
    \hline
    Basis&Support&Suitable signals&Unsuitable signals\\
    \hline
    Fourier&global&sine like&localized\\
    wavelet&local&localized&sine like\\
    \hline
  \end{tabular}
  \caption{Characteristics of Fourier and wavelet basis.}
  \label{tab:fourier-wavelet}
\end{table*}

When reporting computational or measurement results, always
report the mean (average value) along with a measure of variability
(standard deviation(s) or standard error of the mean).


\section{Tips for Good Software}
\label{sec:tips-software}

There is a lot of literature (for example~\cite{hunt99pragmatic} and
\cite{spolsky04software}) on how to write software. It is not the
intention of this section to replace software engineering
courses. However, in the interests of reproducible
research~\cite{schwab00}, there are a few guidelines to make your
reader happy:
\begin{itemize}
\item Have a \texttt{README} file that (at least) describes what your
  software does, and which commands to run to obtain results. Also
  mention anything special that needs to be set up, such as
  toolboxes\footnote{For those who are
  particularly interested, other common structures can be found at
  \url{http://en.wikipedia.org/wiki/README} and
  \url{http://www.gnu.org/software/womb/gnits/}.}.
\item A list of authors and contributors can be included in a file
  called \texttt{AUTHORS}, acknowledging any help that you may have
  obtained. For small projects, this information is often also
  included in the \texttt{README}.
\item Use meaningful filenames, and not \texttt{temp1.py},
  \texttt{temp2.py}. 
\item Document your code. Each file should at least have a short
  description about its reason for existence. Non obvious steps in the
  code should be commented. Functions arguments and return values should be described.
\item Describe how the results presented in your paper can be reproduced.
\end{itemize}


\subsection{\LaTeX{} Primer}
\label{sec:latex-primer}

\LaTeX{} is one of the most commonly used document preparation systems
for scientific journals and conferences. It is based on the idea
that authors should be able to focus on the content of what they are
writing without being distracted by its visual presentation.
The source of this file can be used as a starting point for how to use
the different commands in \LaTeX{}. We are using an IEEE style for
this course.

\subsubsection{Installation}

There are various different packages available for processing \LaTeX{}
documents.
On OSX use Mac\TeX{}
(\url{http://www.tug.org/mactex/}). On Windows, use for example Mik\TeX{} (\url{http://miktex.org/}).

\subsubsection{Compiling \LaTeX{}}
Your directory should contain at least~4 files, in addition to image
files. Images should be in \texttt{.png}, \texttt{.jpg} or
\texttt{.pdf} format.
\begin{itemize}
\item IEEEtran.cls
\item IEEEtran.bst
\item groupXX-submission.tex
\item groupXX-literature.bib
\end{itemize}
Note that you should replace groupXX with your chosen group name.
Then, from the command line, type:
\begin{verbatim}
$ pdflatex groupXX-submission
$ bibtex groupXX-literature
$ pdflatex groupXX-submission
$ pdflatex groupXX-submission
\end{verbatim}
This should give you a PDF document \texttt{groupXX-submission.pdf}.

\subsubsection{Equations}

There are three types of equations available: inline equations, for
example $y=mx + c$, which appear in the text, unnumbered equations
$$y=mx + c,$$
which are presented on a line on its own, and numbered equations
\begin{equation}
  \label{eq:linear}
  y = mx + c
\end{equation}
which you can refer to at a later point (Equation~(\ref{eq:linear})).

\subsubsection{Tables and Figures}

Tables and figures are ``floating'' objects, which means that the text
can flow around it.
Note
that \texttt{figure*} and \texttt{table*} cause the corresponding
figure or table to span both columns.



\section{Summary}

The aim of a scientific paper is to convey the idea or discovery of
the researcher to the minds of the readers. The associated software
package provides the relevant details, which are often only briefly
explained in the paper, such that the research can be reproduced.
To write good papers, identify your key idea, make your contributions
explicit, and use examples and illustrations to describe the problems
and solutions.

\section*{Acknowledgements}
The author thanks Christian Sigg for his careful reading and helpful
suggestions.

\bibliographystyle{IEEEtran}
\bibliography{literature}

\end{document}
